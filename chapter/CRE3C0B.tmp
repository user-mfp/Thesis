\chapter{Background and Motivation}
\label{motivation}

Over time, public places became more and more enriched with all kinds of technology. Nowadays, on nearly every corner something is beeping or blinking and buttons, leavers and knobs make us - their potential users - interact with our environment. This trend does not spare anyone or anything. Even traditionally calm and sophisticated places open up to the possibilities of contemporary technologies.

%-----------------------------------------------------------------------------

%\paragraph{Related Work - Annotations}
%
%\begin{itemize}
	%\item Backgrounds
	%\begin{itemize}
		%\item Historical
		%\item Technical
	%\end{itemize}
	%\item Application areas
	%\item Not to much detail
	%\item Only in respect to the thesis' topic
%\end{itemize}

%-----------------------------------------------------------------------------

\section{Museums}
\label{motivation_museums}

Museums, much like libraries, are foremost seen as a place of knowledge and its preservation. Hence, visitors behave in a very reserved manner. Whilst applying for libraries, museums are willing to involve people instead of merely providing information. Many museums therefore employ guides, who give tours and tell visitors about the exhibits. In addition to their factual knowledge, they also provide interesting anecdotes and other exciting information needed to bond with a certain topic. Apart of instructive and teaching staff, museums have tried many other ways to involve their visitors. One of those is utilizing technology. With time technology evolved, and so did technological augmentations in museums.
\\
The name ''museum'' comes from the ancient greek's ''Museion''. It refers to a sanctified place in honor of a muse~\cite{DeutscherMuseumsbundGeschichte}. Basically, museums are collections of arts and science or at least parts of them on display. In modern history, those collections were of an artistic nature and mostly private. Later, scientific and otherwise cultural museums were established for the general public~[ibid.]. 
\\
One of the first high-tech installation of the modern age was the \textit{Diorama}. In 1821, Louis Jacque MandÃ© Daguerre\footnote{Daguerre is a scene painter and stage designer by trade. He also is the inventor of the first photographic process called daguerreotypy} and the painter Charles Marie Bouton partnered up to develop this spectacle. It is an elaborate combination of painting and lighting~\cite{DioramaDaguerre}. Through ingenious lighting, the paintings became vivid. This way, a diorama could simulate the moods of a whole day within minutes. Thus, it is seen as an early predecessor of the cinema. Even today, although in much smaller size, dioramas are still of certain interest~\cite{DioramaSchneider}.
\\
The first interactive displays appeared at the \textit{Urania} in Berlin around 1889, when they introduces visitor-activated models and a scientific theater. In 1907 the \textit{Deutsches Museum} in Munich also began experimenting with film and mechanical models, which were operated by visitors~\cite{MuseumsHistoryMcLean}. Later, other museums all over the world followed. Since then the 
\textit{\begin{quote}
	''[...] wider museological community's understanding of nature and purpose of interactiveness''\textnormal{~\cite{MuseumsHistoryWitcomb}}
\end{quote}}
has taken shape.
\textit{\begin{quote}''This understanding almost invariably involves:
	\begin{enumerate}
		\item The presence of some technological medium.
		\item A physical exhibit which is added to the main display.
		\item A device which the visitor can operate, involving physical activity.''\textnormal{~\cite{MuseumsHistoryWitcomb}}
	\end{enumerate}
\end{quote}}

As electronics and microchips evolved, computers became popular and affordable. The technological equipment of museums grew with what was available and new kinds of devices and installations appeared. Today, nearly every museum has a certain guide system such as an audio guide. It either leads visitors through the museum on a predefined course or a visitor can choose the track according to a given code for each included exhibit. In 2004, Chou et al.  compared different museum guide systems in various categories, which were considered necessary to provide a user-friendly and informative experience. Expositors, tape machines, CD-players and a PDA were judged. The PDA was most versatile and easy to use system~\cite{MuseumGuideSystems} (see Figure \ref{fig:museum_guide_system}). The described system had the portability of an audio guide, but due to position recognition the PDA would always present the current exhibit. The system could replace common audio guides and immobile information terminals all together. In addition, it still was able to give predefined tours depending on the user's interests.
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{~\cite{MuseumGuideSystems}.}%
\label{fig:museum_guide_system} %
\end{figure}

Yet another chapter was opened, when the internet and wireless communication were introduced. Museums began to also maintain websites. Burgard et al. went a step further, included robotics and build an autonomous tour-guide robot called \textit{RHINO}~\cite{RHINO} depicted in Figure \ref{fig:rhino}. It was able to navigate through the museum freely and without bumping into visitors. On demand, RHINO worked as an information terminal for present visitors and it could be used as a tour-guide as well, because it had a simple build-in web interface. Thus, the museum's contents where simultaneously used by the website and the robotic tour-guide. RHINO was deployed at the \textit{Deutsches Museum Bonn} in 1998 [ibid.].

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{~\cite{RHINO}.}%
\label{fig:rhino} %
\end{figure}

In 2002, a group from the \textit{University of Limmerick} made a survey in \textit{Hunt Museum}. The museum is owned and run by the Hunt-family. Its tradition is to involve the visitors since its early days. Therefor, they had so-called \textit{cabinets of curiosity}~\cite{Hunt1}, special compartments within the exhibition, where additional exhibits were hidden. For example, a curious visitor had to open drawers in order to find a collection of plates. Via this exploration, the visitors became involved. Inspired by their observations, Ciolfi et al. implemented a completely new and interactive part of the exhibition in 2003~\cite{Hunt2}. Two new rooms were introduced. First, there was the \textit{study room} with three interactive devices for getting further information about certain exhibits. They were disguised as a chest, a painting and a desk. The second room, the \textit{room of opinion}, was plain white with plinths, on which visitors could record their interpretations of the intended function of certain exhibits. In  order to manage all the data, a third and hidden room was used to host all the data-servers.

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{~\cite{Hunt1}~\cite{Hunt2}.}%
\label{fig:hunt_museum} %
\end{figure}

The \textit{medien.welten}-exhibition at \textit{Technisches Museum Wien} was not only showcasing technical devices from all eras and genres of modern media, it also invited visitors to make use of some. As Hornecker et al. described in ~\cite{MedienWelten}, throughout the exhibition users were given opportunities to produce their own medial content. The interfaces ranged from an abacus over a telegraph to a whole rebuild of a news-studio from an Austrian TV-channel. Figure \ref{fig:medien_welten} shows those and other installations. Visitors could not only use the devices, but store some of their produced contents in a \textit{digital backpack} [ibid.]. This way, visitors did not only have an exciting experience, but also something to remember it by later.

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{~\cite{Hor06}.}%
\label{fig:medien_welten} %
\end{figure}

%\paragraph{Annotations}
%
%\begin{itemize}
	%\item Historical evolution
	%\begin{itemize}
		%\item Museums are believed to be old fashioned
		%\item Mostly willing to experiment (Examples)
		%\begin{itemize}
			%\item Dioramas
			%\item ...
			%\item Animatronics
			%\item Robotics
		%\end{itemize}
	%\end{itemize}
%\end{itemize}
%
%------------------------------------------------------------------------------------------
%
%\subsection*{Old version}
%
%Museums, much like libraries, are foremost seen as a place of knowledge and its preservation. Hence, visitors behave in a very reserved manner. Whereas this may apply for a library, museums are willing to involve people instead of merely providing information. Many Museums therfore employ guides, who give tours and tell visitors about the exhibits. In addition to their factual knowledge, they can also provide anecdotes and other information needed to bond with a certain topic. Apart of instructive and teaching staff, museums have tried many other ways to involve their visitors more. One of those is employing technology. With time technology evolved, and so did technological augmentations in museums.
%\\
%It may have started with simple mechanics, which moved some models, and later included basic electronics, which illuminated particular exhibits. Microchips and computers became more and more popular and affordable. So, the next step was immanent. There were info-terminals (...) Yet another chapter was opened, when the internet and wireless communication were introduced. Burgard et al. build an autonomous tour-guide robot called RHINO. It was able to navigate through the museum freely without bumping into visitors. RHINO could be used as a tour-guide for present visitors as well as for visitors on the internet, for it had a simple build-in and a web interface [Bur98]. RHINO was deployed at the “Deutsches Museum Bonn” in 1998.
%\\
%In 2002, a group from the University of Limmerick made a survey in the Hunt Museum. The
%museum is owned and run by the Hunt family, whose tradition it was from the beginning to involve the visitors. Therefore, they had so-called cabinets of curiosity [Cio02], special compartments within the exhibition, where additional exhibits were hidden. For example, one had to open drawers in order to find a collection of plates. Via this exploration, the visitors became involved. Inspired by their observations, Ciolfi et al. implemented a completely new and interactive part of the exhibition in 2005. Two new rooms were  introduced. First, there was a study room with three interactive devices for getting further information about certain exhibits. They were disguised as a chest, a painting and a desk. The second room, the room of opinion, was plain white with plinths, on which visitors could record their interpretations of intended function of certain exhibits. In  order to manage all the data, a third and hidden room was used to host all the data-servers [Cio05].
%\\
%Something about [Hor06].

%------------------------------------------------------------------------------------------

\section{Interfaces and Interaction}
\label{motivation_interfaces}

People visiting a museum come from different backgrounds and in various numbers. There can be large groups like a school class on a field trip or a single person strolling around. Their technical and physical abilities might also vary. Hence, an installation's ease of use, especially in a museological context, is of great importance. Because the interface is the only connection between users and the system, it has to be as intuitive and easy to use as possible. It dictates the way of interaction and, therefore, whether the whole systems works or not. A ground breaking system is worth nothing without proper interaction between its operator and it. This presents the need for suitable kinds of input and feedback. Thus, Ben Shneiderman once introduced his \textit{eight golden rules of interface design}:
\textit{\begin{quote}
	\begin{enumerate}
		\item ''Strive for consistency.
	%Consistent sequences of actions should be required in similar situations; identical terminology should be used in prompts, menus, and help screens; and consistent commands should be employed throughout.
		\item Enable frequent users to use shortcuts.
	%As the frequency of use increases, so do the user's desires to reduce the number of interactions and to increase the pace of interaction. Abbreviations, function keys, hidden commands, and macro facilities are very helpful to an expert user.
		\item Offer informative feedback.
	%For every operator action, there should be some system feedback. For frequent and minor actions, the response can be modest, while for infrequent and major actions, the response should be more substantial.
		\item Design dialogs to yield closure.
	%Sequences of actions should be organized into groups with a beginning, middle, and end. The informative feedback at the completion of a group of actions gives the operators the satisfaction of accomplishment, a sense of relief, the signal to drop contingency plans and options from their minds, and an indication that the way is clear to prepare for the next group of actions.
		\item Offer error prevention and simple error handling.
	%As much as possible, design the system so the user cannot make a serious error. If an error is made, the system should be able to detect the error and offer simple, comprehensible mechanisms for handling the error.
		\item Permit easy reversal of actions.
	%This feature relieves anxiety, since the user knows that errors can be undone; it thus encourages exploration of unfamiliar options. The units of reversibility may be a single action, a data entry, or a complete group of actions.
		\item Support internal locus of control.
	%Experienced operators strongly desire the sense that they are in charge of the system and that the system responds to their actions. Design the system to make users the initiators of actions rather than the responders.
		\item Reduce short-term memory load.''\textnormal{~\cite{DesigningTheUI}}
	%The limitation of human information processing in short-term memory requires that displays be kept simple, multiple page displays be consolidated, window-motion frequency be reduced, and sufficient training time be allotted for codes, mnemonics, and sequences of actions. 
	\end{enumerate}
\end{quote}}

Following this guideline should yield a well operable interface. However, there still might be particular difficulties for specialized or novel systems. Especially public user-interfaces bring new factors, which are not explicitly included in Shneiderman's rules. How should an interface behave,
\begin{itemize}
	\item in order to invite users?
	\item on a user's first encounter?
	\item if there are multiple users?
\end{itemize}

The ideal interface should be as intuitive and naturally to use as possible. This requirement was already addressed in 1980 by Richard A. Bolt. He described the \textit{Media Room} at \ac{MIT} shown in Figure \ref{fig:put_that_there} as an office with a chair, a wall-sized screen and other analogue or electronic installations. The room's equipment allowed the user to navigate through the \textit{\ac{SDMS}} called \textit{Dataland}. The user would sit down and had several input-devices at its disposal. One of them was a small device that could measure its position and orientation in space. The device was used to calculate where on the big screen the user was pointing. In combination with simple voice-commands the user was able to create and manipulate geometrical primitives~\cite{PutThatThereUI}.

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{~\cite{PutThatThereUI}.}%
\label{fig:put_that_there} %
\end{figure}

Since then, this seemingly futuristic furnishing could not be established as a common way of interaction. Keyboard and Mouse are still the most widely used input-devices. Meanwhile, touchscreens and voice-recognition are closing the gap though. The principle of \ac{WYSIWYG}\footnote{\ac{WYSIWYG} first came up in the 1970s, when the first office-programs appeared. Due to different resolution-densities of displays and printers, it was necessary to show correct relations of letters and page. Later on, the term was synonymously used for \ac{GUI}-elements.} became of ever greater importance. Many interfaces are designed with Shneiderman's rules and usability in mind. Developments in \ac{HCI} seem promising. More intuitive devices and interfaces are developed and tested thoroughly. 

There are basically two types of interfaces. A \ac{SUI} is designed to be operated by only one user, whereas a \ac{MUI} can be operated by a group of users at once. However, there is no strict distinction between the two. People might look over a \ac{SUI}'s user's shoulder and give instructions, or a lone person could operate a \ac{MUI} on its own. Another factor that influences how people use an interface is the occasion. Public interfaces, such as a kiosk system at a cinema or for photo-developing provide a \ac{GUI} on a touchscreen. Those systems are intended to be used by a single user, but might also be confronted with groups. Azad et al. investigated how groups behave around such kiosks. Most groups approached the interface asynchronously. Meaning, one member is interacting with the system, while the others watch. As time passes, the rest of the group might get more active due to \textit{intra-group communication}.
They further observed, that 
\textit{\begin{quote}
	''there is a semantic, profound difference between pointing and touching. Users who point are communicating ideas within a social group and 		may not want the technology to treat it as input.''\textnormal{~\cite{AzadMultiUI}}
\end{quote}} 
Moreover, inter-group communication is also of great importance. Shyness or frustration may inhibit an individual or group from interacting with a system. Strangers can ease the use, when they act as an example or explain their actions to those shy or frustrated~\cite{PublicUI}.

Interfaces can not only be categorized by their intended demographics. Input- and output-devices dictate the kind of interaction. As mentioned earlier, keyboard and mouse are being replaced with novel technologies. Touchscreens and voice recognition have become established means of input as well. Moreover, novel approaches towards interaction are made and influenced by novel possibilities in technology. Museums in particular strive for innovative interfaces to involve visitors and, therefore, tend to explore many fields of interactive possibilities.
\textit{\begin{quote}
	''Interactive exhibitions are thriving, encouraged by a new approach to museology developed in response to current social demand and a much more participatory philosophy involving a redefinition of the concept of the museum in general and of the science museum in particular. [...] The classic concept of observation has been replaced by that of participation.''\textnormal{~\cite{InteractiveMuseumExhibits}}
\end{quote}}
A \ac{TUI} is a very natural approach. Here, a tangible object represents a digital entity. This could be a virtual object or something more abstract like an operation or property. Those tangibles can be used to interact with a system or even each other. In ~\cite{TangibleUI}, Ullmer et al. described the principle of \textit{token and contraint}, which played an influential role during the conception and is revisited in Chapter \ref{conception_constraints}. Two name-giving types of tangibles are involved, tokens and constraints. They have two phases of interaction. At first, tangibles can be associated, which means that their physical shape dictates, whether tokens will or will not work with a particular constraint. After that, the constraint's properties dictate the further way of interaction as shown in Figure \ref{fig:tui}a,b,c. In comparison to ordinary interfaces a \ac{TUI} offers more haptic perception. This could increase a user's attention to the interface and as a consequence their involvement with a possibly related exhibit.

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{~\cite{TangibleUI}.}%
\label{fig:tui} %
\end{figure}

Apperceptive and playful interfaces might raise visitors' involvement. Groups of visitors tend to spend more time with an interactive exhibit, because the majority wants to make the experience for itself~\cite{InteractiveMuseumExhibits}.

\ac{VR} provides a less tangible approach. Contemporary \ac{VR}-systems offer a way to display and manipulate \ac{3D} data in real-time. Users can be immersed into vast, \ac{3D} environments, which are projected on huge stereoscopic displays or shown by a \ac{HMD}\footnote{Recent, distinct examples are \textit{Occulus Rift} and \textit{Google Glasses}. While Occulus Rift provides a completely closed solution for \ac{3D} \ac{VR}-environments, the Google Glasses are an \ac{AR}-approach. Here, additional information is displayed on top of perceived reality.}. Those systems require a special kind of interaction to either navigate through or select objects in the virtual environment. Therefore, special interaction metaphors were developed. Proper navigation can be realized via any input-device capable of six \ac{DOF}\footnote{One \ac{DOF} is either translation along or rotation around one spacial axis. Hence, there are six possible movements in \ac{3D} space.} and is rather familiar. But, since navigating to each object in order to select and manipulate it is inconvenient, a separate metaphor for interacting with objects had to be developed as well. Thus, a pointing device was introduced. In order to calculate its correct position and direction it has reflective markers in a unique pattern, which are then tracked by a system of infrared cameras (see Figure \ref{fig:vr_pointing_device}a)~\cite{PointingDevicesVR}. A virtual ray into the scene is calculated accordingly. Basically, objects can be selected by pointing at them and triggering selection in some way. \textit{A survey of \ac{3D} object selection techniques for virtual environments} showed that 29 of 31 reviewed techniques were based on ray-interaction. The remaining two used a hand avatar like in Figure \ref{fig:vr_hand_avatar}b. Both of them track a user's hand and one also applies ray-based leverage to extend reach~\cite{VRObjectSelectionCnG}.

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{a~\cite{PointingDevicesVR}, b~\cite{VRObjectSelectionCnG}.}%
\label{fig:vr_hand_avatar} %
\end{figure}

As mentioned earlier, keyboard and mouse are established means of input, though there are more natural ways of input though. Humans have been communicating with gestures for ages. With this in mind, \textit{gestural interaction} arose as a concept in \ac{HCI}. In \cite{GestureInteraction} five basic categories of gesture styles are defined.	All those gestures can be applied to two- and three-dimensional interfaces. \textit{Deictic} gestures are defining a location and include all varieties of pointing gestures [ibid.]. They range from the cursor on a desktop PC to the \ac{VR}-pointing devices mentioned above. \textit{Manipulative} gestures are used for translation, rotation, and scaling [ibid.]. Here, the ''pinch to zoom''-gesture for many touch-based devices is probably the most commonly known. More abstract gestures are \textit{semaphoric} and {language} gestures [ibid.]. They consist of designated signs or movements and can be static or dynamic. The best example for static gestures is sign language. Air traffic controllers use flag waving to guide planes into parking positions by semaphoric gestures. The last category is \textit{gesticulation} [ibid.]. In contrast to semaphoric gestures, gesticulation is purely natural and does not have to be learned. Gestures often appear in combination with speech, why they are also called \textit{coverbial} gestures.

Gestures are naturally motivated. Thus, gesture-based interfaces should be intuitive to interact with. Through the introduction of smart phones and tablet computers touch-based interaction and gesture-based interfaces are getting more and more relevant. In 2003, the \textit{EyeToy for PlayStation2} began to show the possibilities of \textit{free-hand gestures}. A few years later, Microsoft began selling the \textit{Kinect for Xbox 360}. Independent drivers and software for it were developed almost immediately, which enabled developers and researchers to utilize the system's capabilities on regular computers. The official \ac{SDK} and \textit{Kinect for Windows} followed about half a year later. Other devices like \textit{ASUS Xtion PRO} followed working with the identical internal hardware. The more detailed hardware specifications will be explained in Chapter \ref{conception}. This development introduced a low cost solution for user-tracking, whilst the aforementioned tracking systems for \ac{VR} are very expensive. Several interfaces were developed making use of the hardware's potential. 
\\
The \textit{Data$^3$} is an interface based in a Kinect sensor to interact with a database~\cite{DataCube}. It is an approach to visually handle multidimensional datasets. Therefore, the gestures of a user are interpreted and recognized by a middleware. This middleware then produces events upon which the Data$^3$-interface changes the view on the \ac{3D} dataset or certain properties about it. Although the input data provided by the depth sensor is three-dimensional, the gestures that are interpretable are restricted to one or two axes [ibid.].
\\
A similar approach is followed by \textit{Kinoogle}, which is a \textit{natural user interface}~\cite{Kinoogle}. Here, several gestures were defined to navigate in \textit{Google Earth} and \textit{Street View}. The four gestures depicted in Figure \ref{fig:kinoogle} were defined to operate the \ac{GUI} of Google Earth. Therefore, \textit{panning}, \textit{zooming}, \textit{rotate}, and \textit{tilt} gestures are mapped to mouse and keyboard inputs.

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{a~\cite{PointingDevicesVR}, b~\cite{VRObjectSelectionCnG}.}%
\label{fig:kinnogle} %vire gesten zur steuerung
\end{figure}

For each gesture, all axes are monitored to recognize an event. However, an event is triggered by certain changes on one or two axes. For instance, the rotation gesture is based on the relation of both hands of the user to each other. Therefore, their x- and y-values are observed and evaluated~\cite{Kinoogle}. The remaining gestures work in a similar fashion. 
\\
In virtual \ac{3D}-environments low cost depth sensors are used as well. Thus, a Kinect can be utilized to track a user inside a \ac{CAVE}\footnote{A \ac{CAVE} is a special \ac{VR}-setup with multiple screens. This produces more immersion than an ordinary single screen-setup. To provide correct perspectives for a user, its head position and orientation have to be reliably tracked. Otherwise, there might be unpleasant artifacts or even errors between the differentC screens.} to calculate correct perspectives for him or her~\cite{KinectCAVE}. Figure \ref{fig:kinectCAVE}a and b show a user inside the \ac{CAVE} once as a standard image and once as depth image.

\textbf{F I G U R E}
\begin{figure}[H]%
\includegraphics[width=\columnwidth]{../pics/blank.eps}%
\caption{a~\cite{PointingDevicesVR}, b~\cite{VRObjectSelectionCnG}.}%
\label{fig:kinectCAVE} %beide Bilder aus der Cave
\end{figure}

Jung et al. are tracking the shoulders and head of a user. Those tracked points are then combined to form an orientation matrix upon which a \textit{sufficiently correct perspective} can be displayed~\cite{KinectCAVE}. If the tracking data is flawed, the perspective is also compromised. Hence, such a system has to be robust and reliable. 

As a consequence of these developments, the performance and suitability of low cost tracking solutions for \ac{VR}-tasks was examined. Ren and O'Neill stated that
\textit{\begin{quote}
	''More and more information and other content is visualized and manipulated in 3D, bringing a corresponding increase in the importance of effective and usable 2D user interfaces.''\textnormal{~\cite{FreehandSelectionCnG}}
\end{quote}}
They conducted two kinds of test. First, they looked into \ac{2D} interaction techniques such as touchscreens and \textit{freehand \ac{3D}} interaction and described similarities and differences. Accordingly, both techniques' \ac{WYSIWYG}-approach makes them spontaneous and direct. This natural \textit{walk-up-and-use} interaction style decreases the interaction cost for any possible user. Further, users are able to move freely, because there are no extra devices to pick up and operate~\cite{FreehandSelectionCnG}.
In the second test, the low cost solution was evaluated for common \ac{3D} interaction techniques in \ac{VR}-environments. Thereupon, Ren et al. came up with a \textit{design guideline for \ac{3D} freehand interaction} [ibid.].
\begin{itemize}
	\item Avoid single actions with either high accuracy or keeping the hand up for long.
	\item Use goal crossing~\cite{CrossingBasedInterfaces} as a trigger.
	\item Map complex \ac{3D}-movements on \ac{2D} interaction.
	\item Use the extra dimension as a trigger.
	\item Avoid uncomfortable hand or arm positions.
\end{itemize}
In the end, Ren and O'Neill concluded: 
\textit{\begin{quote}
	''Freehand gestural selection enabled by a single low cost camera is a potentially valuable technique enabling flexible, low configuration interaction in 3D environments, without any requirement for dedicated devices to be worn on or carried by the user. With appropriate designs, freehand 3D interaction can share the appealing fluidity and immediacy of currently popular multi-touch surfaces, [...] enabling walk-up-and-use access to services, holding the promise of wide applications for ordinary users in everyday life.''\textnormal{~\cite{FreehandSelectionCnG}}
\end{quote}}

%\begin{enumerate}
	%\item Anzahl - Interfaces
	%\begin{enumerate}
		%\item Single-user interface
		%\item Multi-user interface
	%\end{enumerate}
	%\item Eingabemethoden - Interaction
	%\begin{enumerate}
		%\item Established Devices (Keyboard, Mouse, and Touch interaction)
		%\item Tangible interaction~\cite{TangibleUI}
		%\item VR-interaction~\cite{VRObjectSelectionCnG}
	%\end{enumerate}
%\end{enumerate}

%------------------------------------------------------------------------------------------

%\section{Public Interfaces}
%\label{motivation_single}
%
%\paragraph{Public Interfaces - Annotations}
%
%\begin{itemize}
	%\item Technologies for input / interaction
	%\item Hands-free
	%\item Gestural interaction (Kinect)
%\end{itemize}

%------------------------------------------------------------------------------------------

%\paragraph{Single User-Interfaces - Annotations}
%
%\begin{itemize}
	%\item Human behavior concerning public interfaces
	%\begin{itemize}
		%\item self-service at train-stations
		%
		%\item public interfaces, such as Tobias Fischer's \textit{SMS-Schleuder fuer Fassaden}
		%\item Intuitive usage vs. inhibition
	%\end{itemize}
%\end{itemize}

%------------------------------------------------------------------------------------------

%\section{Tangible Interfaces}
%\label{related_work_tangible}
%
%\begin{itemize}
	%\item Paper: 'Token+constraint' Ullmer/Ishii/Jacob
	%\item This way, even orientation could influence the type of information. 
%\end{itemize}

%------------------------------------------------------------------------------------------

%\section{Virtual Reality}
%\label{motivation_vr}
%
%\paragraph{Annotations}
%
%\begin{itemize}
	%\item Input
	%\begin{itemize}
		%\item Metaphors and devices
		%\begin{itemize}
			%\item Navigation and selection in 3d space
			%\item Possibilities
			%\item Difficulties
			%\item Constraints
		%\end{itemize}
	%\end{itemize}
	%\item Output
	%\begin{itemize}
		%\item Ordinary screen
		%\item Stereoscopic displays
		%\item \ac{HMD} such as Oculus Rift
	%\end{itemize}
%\end{itemize}

%This was only a short overview of some existing interfaces and forms of input. There are more specialized interactions like tracking eye-movements or \ac{BCI}. The examples given above represent a general insight of how to interact with a system, as well as the breadth and versatility of possibilities.

%------------------------------------------------------------------------------------------

\section{Goal of this Work}
\label{motivation_goal}

After having gathered experiences with several of the aforementioned interaction techniques, I intended to combine those experiences into a unique interface. Especially the intuitive motivation behind tangibles, touch-based interfaces and the immersive nature of \ac{VR}-environments are interesting fields.
\textit{\begin{quote}
	''Unfortunately, current user interfaces often lack adequate support for 3D interactions: 2D desktop systems are limited in cases where natural interaction with 3D content is required, and 3D user interfaces consisting of stereoscopic projections and tracked input devices are rarely adopted by ordinary users. The success, both in research and commercial applications, of recent touch-based interfaces raise an interesting possibility. Can the immediacy, control, and expressiveness of recent touch-based natural interfaces be applied to 3D problems?''\textnormal{~\cite{ForewordCnG}}
\end{quote}}
I wanted to answer this question. But before that, several issues had to be dealt with. First, a suitable cooperation partner had to be found. As described earlier, a museum in Weimar was ideal. I needed access to an unbiased audience and topical expertise. Second, we would have to agree on a feasible concept and clarify responsibilities. Subsequently, the system would have to be developed and implemented before the final installation could be evaluated in its real-world environment. Finally, some small adjustments could be made and larger improvements or augmentations should be discussed. 
\\
A museum was found, concepts were made and a \ac{TUI} or an alternative concept for interaction were required. The \textit{SMSlingshot} already combines a handheld device with \ac{3D} interaction to some extend. It is a tangible device, which enables a user to splat short massages onto a facade~\cite{SMSlingshot}. The device's affordance is clear, since most people are aware of the functionality of both a phone-sized keypad and a slingshot. Nevertheless, the device can only be used by one user at a time. This is where \textit{Shared Encounters} come into play. There are different types of interrelated spaces, which offer different grades of interaction between a user and either the interface or others~\cite{UrbanHCI}. In course of my work, those two key concepts will reappear in more detail.

In the end, my answer was using the most intuitive device there is: a user's body itself.

My focus lied more on the presentation than on the administration software, because it will be used most of the time. Nevertheless, I implemented the whole system to be as versatile as possible and to allow others to use the system almost anywhere. It is not a customized solution for this one installation. 
